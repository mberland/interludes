{"cells":[{"cell_type":"markdown","source":["In this interlude, we are going to use the wonderful, beautiful open data from the Cleveland Museum of Art to generate new, fake art pieces. The idea here is to think aboutt he power and limitations of open data, of historical bias, and of the problems of language in the public space.\n","\n","This chapter comes with a BIG warning: A lot of art is racist, developed in patently racist societies using racist language. The same trigger applies to sexism, colonialism, homophobia, anti-semitism, whatever. I feel confident in saying that this is not the fault of the Cleveland Museum of Art. To remove all art created in racist societies is to remove all art. That said, it is shocking to see how quickly the simple statistical trick shown below will reproduce, say, sexist modes of language, simple because they are so over-represented through the historical artifacts and their descriptions."],"metadata":{"id":"z24SVSyIn8x2"},"id":"z24SVSyIn8x2"},{"cell_type":"markdown","source":["As with all interludes, we start by bringing in all of the `library` modules that we will need. In this case, we also need to download a separate toolkit of language information about English as a spoken/written (\"natural\") language; the use of the term \"natural\" for spoken/written English language could be another whole book, perhaps."],"metadata":{"id":"raDMaX8KpLBt"},"id":"raDMaX8KpLBt"},{"cell_type":"code","execution_count":null,"id":"2acfb357-f7fe-476c-a1d5-a62a11349e6f","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2acfb357-f7fe-476c-a1d5-a62a11349e6f","executionInfo":{"status":"ok","timestamp":1651069719158,"user_tz":300,"elapsed":526,"user":{"displayName":"matthew berland","userId":"00278639104689939753"}},"outputId":"a344b4fb-e941-4aed-ffb6-0e363490e84f"},"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":1}],"source":["import json # to parse the data format\n","import urllib.request # to get data from the web\n","import pickle # the storage format for python\n","import nltk # \"natural language toolkit\"\n","import re # regular expression library lets us search text\n","from random import choice, random \n","from os.path import exists # this asks \"does this file exist?\"\n","from bs4 import BeautifulSoup # this can turn web text into human-readable text\n","from collections import Counter # helpful to create tallies\n","import string\n","\n","# the first time we use the natural language toolkit (nltk)\n","# we need to download the data\n","nltk.download('punkt')"]},{"cell_type":"markdown","source":["Now we need to download the information from the Cleveland Museum of Art's database. That said, we do not want to download all of it every time we want to use it, so we save it to disk in a format that Python (the computer language) prefers; this is called `pickle` (and the file ending on a pickle file is, at least for me, `.pkl`)."],"metadata":{"id":"e3sBNiqdplB4"},"id":"e3sBNiqdplB4"},{"cell_type":"code","execution_count":null,"id":"d24204d9-e1b7-4cf3-a77e-c4789b375c22","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d24204d9-e1b7-4cf3-a77e-c4789b375c22","executionInfo":{"status":"ok","timestamp":1651069722090,"user_tz":300,"elapsed":2934,"user":{"displayName":"matthew berland","userId":"00278639104689939753"}},"outputId":"1d201676-1d85-426c-fa3c-f0c62b41510b"},"outputs":[{"output_type":"stream","name":"stdout","text":["DATA LOADED: 64137 artworks.\n"]}],"source":["# we would like to only ask for data from the lovely museum once,\n","# so we need to store it locally\n","data_filename = \"./cleveland_data.pkl\"\n","\n","# if we have not already made a data file, we need to make one\n","if not exists(data_filename):\n","\n","    # the wonderful people of the cleveland art museum\n","    # make a lot of data open and free.\n","    # read more here: https://openaccess-api.clevelandart.org/\n","    # CLEVELAND_URL = \"https://openaccess-api.clevelandart.org/api/artworks/\"\n","    CLEVELAND_URL = \"https://github.com/ClevelandMuseumArt/openaccess/raw/master/data.json\"\n","\n","    # we need to get the data from them, and this is how they suggest to do it:\n","    with urllib.request.urlopen(CLEVELAND_URL) as cleveland_json:\n","\n","        # json is the simple and human-readable data format they use\n","        cleveland_raw_data = json.loads(cleveland_json.read().decode(\"utf-8\"))\n","\n","        # pkl.dump puts all that data in a file we can use locally\n","        pickle.dump(cleveland_raw_data,open(data_filename,\"wb\"))\n","\n","# just to verify we're using local data, we will only use data loaded from disk\n","art_data = pickle.load(open(data_filename,\"rb\"))\n","\n","# this tells us how many artworks were in that query above\n","print(f\"DATA LOADED: {len(art_data)} artworks.\")"]},{"cell_type":"markdown","source":["Now that we have loaded our artworks, we need to get the descriptions of the art. We are not going to look at the visual components of the art - just their descriptions."],"metadata":{"id":"simGY8DVqCR1"},"id":"simGY8DVqCR1"},{"cell_type":"code","execution_count":null,"id":"c198458f-bd31-4d1c-8cb4-965ffb56d82e","metadata":{"id":"c198458f-bd31-4d1c-8cb4-965ffb56d82e"},"outputs":[],"source":["# we are just using the descriptions of all the artworks\n","# no titles, no artists, nothing.\n","all_descriptions =  [elt['wall_description'] for elt in art_data if 'wall_description' in elt and None != elt['wall_description']] + \\\n","                    [elt['digital_description'] for elt in art_data if 'digital_description' in elt and None != elt['digital_description']]\n","\n","# beautiful soup takes the \"HTML-like\" descriptions and makes them raw text\n","soup = BeautifulSoup(\" \".join(all_descriptions))\n","descriptions = \"\".join([c for c in soup.text])\n","\n","# nltk does the hard job of turning all the words into a nice sequential list\n","# you'd think that simply separating by space does the job\n","# but that, again, is a bias toward simple sentences.\n","# for instance, it's easy to see how: \"You have a cup.\" becomes \n","# [\"You\",\"have\",\"a\",\"cup\",\".\"] but sentences \n","# like \"Bob's cup is at St. Germain\" are harder to parse.\n","art_words = nltk.word_tokenize(descriptions)"]},{"cell_type":"markdown","source":["Now that we have the descriptions, we need to find a simple way to statistically encode those descriptions. We are using a simple, but effective, idea called the \"bigram\"; this is how autocorrect historically makes its guesses. What's the most likely word to follow the current\n","warp? Sorry, I meant \"word\" not \"warp\"."],"metadata":{"id":"pV6wGX_XqkB7"},"id":"pV6wGX_XqkB7"},{"cell_type":"code","execution_count":null,"id":"f2f87bbe-7aa1-420e-aeca-e0ee61b44954","metadata":{"id":"f2f87bbe-7aa1-420e-aeca-e0ee61b44954"},"outputs":[],"source":["# strip out punctuation that makes parsing and generating harder\n","# note ALL the bias implicit here\n","# in many English AND non-English texts and names, these punctuation are crucial\n","# but we are just throwing them away.\n","letters = set(descriptions)\n","# print(letters)\n","unwanted_punctuation = set([c for c in letters if not (re.match(\"\\w\",c,flags=re.A) or c in \".',\")])\n","# print(unwanted_punctuation)\n","def is_punctuated(word):\n","  for letter in word:\n","    if letter in unwanted_punctuation:\n","      return True\n","  return False\n","art_words = [word for word in art_words if not is_punctuated(word)]\n","\n","# The key to our algorithm is something called a bigram\n","# Our bigrams are every set of two words in a row.\n","# \"A cat sits.\" -> (\"a\",\"cat\"),(\"cat\",\"sits\")\n","# 'zip' is a comamnd python that takes two lists \n","# and make a new list that groups each of the same-located items, \n","# e.g., zip([1,2],[3,4]) -> [(1,3),(2,4)]\n","# so we passed in two equally sized lists of all words in order, \n","# with the second list offset from the first list by one word.\n","art_bigrams = zip(art_words[:-1],art_words[1:])"]},{"cell_type":"markdown","source":["Now we can figure out the specific \"likelihood\" that any particular word is following another word. We create a big \"dictionary\" which is a bit like a spreadsheet where our code can \"look up\" these likelihoods. "],"metadata":{"id":"Qz_KVfXUjy7e"},"id":"Qz_KVfXUjy7e"},{"cell_type":"code","execution_count":null,"id":"72f78767-06f3-4fd0-b46b-0385410f0896","metadata":{"id":"72f78767-06f3-4fd0-b46b-0385410f0896"},"outputs":[],"source":["# now we want to make a big lookup \"dictionary\" of \n","# all the bigrams such that if we look up the first\n","# word of the two, we get a list of every word that might \n","# follow it.\n","art_chances = {k.lower(): [] for k in art_words}\n","for b in art_bigrams:\n","    art_chances[b[0].lower()].append(b[1])"]},{"cell_type":"markdown","source":["At points, we should check our work. What words follow, say, \"ancient\"?\n","There's a handy tool in Python (`Counter`) to count up lists and show us the most common ones."],"metadata":{"id":"OydrEDMgnrYH"},"id":"OydrEDMgnrYH"},{"cell_type":"code","source":["Counter(art_chances[\"ancient\"]).most_common(5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"baJhTEG-nlOm","executionInfo":{"status":"ok","timestamp":1651069778119,"user_tz":300,"elapsed":8,"user":{"displayName":"matthew berland","userId":"00278639104689939753"}},"outputId":"9c2dca25-f9ce-49da-8b9f-10a70d3e2eba"},"id":"baJhTEG-nlOm","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('Greek', 50), ('Roman', 41), ('tombs', 41), ('Egyptian', 22), ('India', 21)]"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["I see `[('Greek', 50), ('Roman', 41), ('tombs', 41), ('Egyptian', 22), ('India', 21)]`.\n","\n","That means that: the word `Greek` follows `ancient` the most often - 7 times in our data; `Rome` follows it 6 times; and so on. This makes sense, so we can move on to generate some new art descriptions! \n","\n","The idea in the code below is that we want to generate sentences based on those likelihoods. "],"metadata":{"id":"QxNtaRhjoORX"},"id":"QxNtaRhjoORX"},{"cell_type":"code","execution_count":null,"id":"eccb4fd2-47a4-46f0-b504-6a8d69da0db8","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eccb4fd2-47a4-46f0-b504-6a8d69da0db8","executionInfo":{"status":"ok","timestamp":1651069797700,"user_tz":300,"elapsed":19586,"user":{"displayName":"matthew berland","userId":"00278639104689939753"}},"outputId":"569437dd-64c3-4076-dc7c-34f763cc9033"},"outputs":[{"output_type":"stream","name":"stdout","text":["Planning and beauty, including rites, surrounded by the sculpture as a decidedly personal visual terms'' da Firenze on a place, halfway between 1389 and Erlangs focus for Cowan's magnificent decoration of contemplative, but deviated from Heike Monogatari, while her husband is not the empty and the 1880s.\n","Textile with the inclusion of hours perhaps Cardinal Francisco Jimenez was an established and his head, marches, Genesis, Mexico's frontispiece.\n","Multicolored acanthus leaves, and enrich learning her friend, the prince, are an industrys fall on numerous occasions and antique manuscripts produced seventeen of intense colors and wife of a in which typically feature a child god for his name because hot milk to echo the right represents makes etchings, but for the rightmost horse races, mundane, was an advertisement reading.\n","Other urban density of sculptures in its place mats and important oracle at the first to Alexander Bening, the flowers, Lucky charm of steel.\n","Designed by casting process is linen tunic decorated with Salomon's hand, and decoration is thoroughly modern age style originated by Michelangelo, the artist developed in the Late and Mrs. Samuelson to build it.\n","Lacquer stand, birds, particularly taken up and the flattened rim.\n","Over a hallmark of deluxe copies of Burchfields perception.\n","1,200 degrees from the reproduction in an exposed, monasteries, whose hair that the figure.\n"]}],"source":["# now we just need to generate some new descriptions\n","# as you might guess from our very simple algorithm,\n","# the results will be weird. there's a chance they'll be \n","# racist, homophobic, and/or any number of other terrible \n","# things. there's some question of whether that means we \n","# should allow them to randomly generated and potentially \n","# upsetting/damaging or whether specifically excising\n","# problematic language is erasing the real, colonialist history of art.\n","\n","# let's make no more than 10 sentences, this is easily changed\n","num_sentences = 10\n","for _ in range(num_sentences):\n","\n","    # we need to start our sentence with a random word!\n","    prev_word = choice([word for word in art_words if re.match(\"\\w\",word) and len(word) > 3])\n","    word_number = 0\n","    sentence = \"\"\n","    \n","    # end sentences at a '.'\n","    while \".\" != prev_word:\n","      \n","        # this is the crux\n","        # the next word will be randomly chosen from the \n","        # list of words/punctuation (\"tokens\") that\n","        # follow the current word in the text\n","        # if \"of\" follows \"book\" 80% of the time,\n","        # then that list (art_chances[\"book\"]) includes 80% \"of\"s\n","        # and that should be the word we choose 80% of the time.\n","        new_word = choice(art_chances[prev_word.lower()])\n","        \n","        # capitalize the first word of a sentence\n","        if (0 == word_number):\n","            prev_word = prev_word.title()\n","        word_number += 1\n","        \n","        # don't put a space between a word and its possessive\n","        # but do put space between most other tokens.\n","        sentence += f\"{prev_word}\"\n","        if not (re.match(\"\\W\",new_word) or \"s\" == new_word): #punctuation\n","            sentence += \" \"\n","        \n","        # move to the next word\n","        prev_word = new_word\n","  \n","    # a lot of the generated sentences are junk! \n","    # throw away very short ones.\n","    if word_number > 4: # throw away junk sentences\n","        print(f\"{sentence}.\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"colab":{"name":"CH05 Interlude - Museums.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":5}